\documentclass[10pt,reqno,a4paper]{article}

\usepackage[brazil]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{bbm}
\usepackage{enumerate}
\usepackage{microtype}
\usepackage{lmodern}
\usepackage{suffix}
\usepackage{notation}
\usepackage{biblatex}
\addbibresource{refs.bib}
\usepackage{graphicx}
\graphicspath{ {./images/} }

\title{Triangulação de Delaunay}
\author{Nathan Benedetto Proença}
\date{6 de dezembro de 2018}

\begin{document}
\maketitle
\section{O Algoritmo}

O algoritmo implementado é o descrito no capítulo 9 de \cite{DeBerg},
e foi discutido em aula. Isso facilitou muito a implementação, por me dar
uma descrição clara da visão geral do que é feito.

A principal ideia é fazer uma construção incremental, que mantém triangulações
parciais. Para cada novo ponto, é necessário encontrar qual triângulo o contém
e subdividí-lo. Além disso, é necessário inverter as arestas que deixam de
pertencer à triangulação. Uma análise probabilística permite concluir que
este algoritmo tem complexidade esperada $O(n\lg n)$, e que o consumo de tempo
é dominado pelo problema de localização na estrutura de dados.

A estrutura de dados é um DAG, onde cada nó é um triângulo de alguma
triangulação parcial que construi. Mantive dois invariantes:

\begin{enumerate}
    \item Um triângulo está na triangulação atual se e somente se ele
        não contém filhos no DAG.
    \item Para todo triângulo que não está na triangulação atual, a união da
        área dos filhos dele no DAG cobre a área do triângulo.
\end{enumerate}

Assim, a busca se torna extremamente simples. Começando da raíz do DAG,
enquanto eu estiver num nó que tem filhos, eu avanço para o primeiro nó
que contém o ponto que estou procurando. Note que a busca \emph{não trata
nenhum caso especial}. Ela retorna algum triângulo da triangulação atual
que contém o vértice. Esta decisão de implementação é interessante
por diminuir o trabalho na parte do algoritmo que domina a complexidade.

Infelizmente isto não foi o bastante para tornar meu algoritmo eficiente,
pois acabei esbarrando em outro gargalo na implementação.

De qualquer maneira, com um triângulo que contém o ponto, posso checar
se ele já é um dos vértices, se ele está em alguma aresta, ou se ele
está no interior do triângulo. Tratei cada caso separado.

\section{Pontos no infinito}

Abordei a forma de representar pontos no infinito de uma maneira mais
teórica, começando com como definir o que eu queria dizer com ``pontos
no infinito''.

A posição dos pontos é vital para as decisões tomadas pelo algoritmo,
principalmente na escolha de quais arestas devem ser invertidas. Não basta
ter 3 pontos fora do fecho convexo da entrada, e tampouco parece ser o
bastante ter um triângulo que contenha o fecho convexo da entrada.
Por isso, apenas dilatar os pontos por alguma constante específica me
pareceu uma forma ruim de resolver o problema.

O paper \cite{guibas1985} descreve diversas primitivas que podem ser utilizadas
para se calcular diagramas de Voronoi. Entre estas, ele demonstra que o teste
de pertencimento de um ponto ao círculo determinado por outros três pontos pode
ser feito ao se analisar o sinal de um determinante. O outro teste que precisava
fazer também envolve analisar o sinal de um determinante --- o teste de
\texttt{Esquerda}.

Para efetuar os cálculos, eu \emph{parametrizei os determinantes com respeito
a uma constante de dilatação}.  Seja $\alpha$ um número real positivo, e seja
$u$ um ponto no plano. O ponto $\alpha u$ é o mesmo ponto dilatado a partir da
origem.  Se interpretar um ponto no infinito como \emph{comportamento de $\alpha u$
para $\alpha$ suficientemente grande}, consigo implementar minhas primitivas
de maneira apropriada.

Seja $\alpha$ um real positivo, e $a, b$ e $c$ pontos no plano. Denotando
$a \wedge b \coloneqq \texttt{area2}(a, b)$, temos que
\[\texttt{Esquerda}^+(a,b,c) \iff (b - a) \wedge (c - a) > 0.\]
Mais ainda, note que como $a \wedge a = 0$ para todo $a$, temos também
que $a \wedge b = - b \wedge a$. Assim, podemos concluir que
\[(b - a) \wedge (c - a) = a \wedge b + b \wedge c + c \wedge a.\]
Como $a \wedge b$ é um determinante, posso calcular o valor deste em função
de $\alpha$. Mais ainda, a função será um polinômio em $\alpha$.
Se, por exemplo, $a$ é um ponto no infinito, podemos escrever $a = \alpha \bar{a}$,
e afirmar que
\[a \wedge b = (\alpha \bar{a}) \wedge b = \alpha (\bar{a} \wedge b).\]
Logo, o termo $a \wedge b$ soma $(\bar{a} \wedge b)$ no coeficiente de $\alpha^1$
no polinômio resultante. Se $b$ também é um ponto no infinito, podemos escrever
$b = \alpha \bar{b}$. Neste caso, concluimos que o termo $a \wedge b$ contribui
$\bar{a} \wedge \bar{b}$ para o coeficiente de $\alpha^2$.

Assim, observando quais pontos são dilatados por $\alpha$, consigo calcular
o polinômio em $\alpha$ definido por $(b - a) \wedge (c - a)$.  Como queremos
apenas obter o sinal da expressão para um $\alpha$ suficientemente grande,
basta devolver o sinal \emph{do coeficiente não nulo da maior potência}.

Implementei esta solução para ambas as primitivas, tanto o teste de esquerda
quanto o de pertencimento ao círculo.  De fato, no código, minha função
$\texttt{e\_in\_circle6}$ chama a função $\texttt{e\_area2}$, e calcula
o polinômio relevante.

Uma consequência positiva desta abordagem é que \emph{se a entrada é
dada por números inteiros, minha implementação trabalha apenas com
aritmética inteira}. Ou seja,posso garantir que os cálculos estão corretos,
e que não há erros de precisão.

Contudo, as contas no caso de entrada inteira são extremamente custosas. Se
o valor absoluto das coordenadas da entrada atingem um valor $C$, as contas
envolvem grandezas da ordem $C^4$. Logo, se a entrada tiver coordenadas
maiores do que $2^{16} = 65536$, o algoritmo precisa de mais do que 64
bits para representar as grandezas com que opera. Logo, para entradas deste
tipo a implementação começa a trabalhar com precisão arbitrária, o que a
impacta bastante o tempo de execução. Dos testes que fiz, utilizar precisão
arbitrária ao invés de ponto flutuante torna o algoritmo 3 vezes mais custoso.

\section{Animação}

Animei três aspectos do algoritmo, todos relacionados à estrutura de dados. O primeiro,
mais direto, é de representar a solução parcial que tenho, garantindo que os triângulos
que estão na minha solução aparecem na figura. A segunda é mostrar os triângulos que
considero na parte de localização, para animar o aspecto mais ``local'' do algoritmo.
Além disso, toda aresta cuja legalidade é testada é colorida de amarelo. Se ela é legal,
a torno verde antes de prosseguir com o algoritmo. Se não, a torno vermelha, e faço
a inversão.

Isto ressalta os aspectos interessantes do funcionamento do algoritmo. Um, o
processo de localização do ponto, e depois o trabalho necessário para corrigir a
triangulação.

\section{Eficiência}

Para justificar a implementação probabilística, contabilizei quantas arestas eram
invertidas. Apesar de não ser o gargalo do algoritmo, que é a busca na estrutura
de dados, ao construir um caso onde são necessárias $\Omega(n^2)$ inversões já
torno evidente a vantagem da aleatorização. Criei um caso onde o algoritmo
determinístico tem comportamento quadrático, e rodei meus testes nele.
Estes casos podem ser visualizados ao se abrir as entradas da forma
\texttt{bad\_incr\_}.

\begin{figure}[h]
    \centering
    \caption{Algoritmo probabilístico no caso construído.}
    \includegraphics[width=0.8\textwidth]{flips_boxplot.png}
    \label{fig:boxplot}
\end{figure}

\begin{figure}[h]
    \centering
    \caption{Quantidade linear de inversões no algoritmo probabilístico.}
    \includegraphics[width=0.8\textwidth]{linear_flips.png}
    \label{fig:linear_flips}
\end{figure}

Para cada potência de 2 entre 16 e 1024, executei o algoritmo 256 vezes e contabilizei
as inversões de arestas que foram feitas. Com estes dados, construí o boxplot 
\ref{fig:boxplot}, que evidencia que a média de inversões está bem perto de $2n$.
Este comportamento fica ainda mais evidente na figura \ref{fig:linear_flips}, onde
além dos pontos encontrados, temos as retas $y = x/2$, $y = 2x$ e $y = 4x$.

O livro limita a quantidade média de \emph{triângulos criados em cada iteração do algoritmo}
por $9$. Ao ser inserido, cada ponto cria 3 triângulos, e mais um para cada aresta que é
invertida. Logo, nos experimentos que fiz, observei em média $5$ triângulos criados em
cada iteração do algoritmo. Isso sugere que talvez exista uma análise mais limpa do que a
feita no livro. A figura \ref{fig:linear_flips} também passa a impressão de que a variância
da quantidade de inversões cresce linearmente com o tamanho da entrada.

\begin{figure}[h]
    \centering
    \caption{Algoritmo determinístico.}
    \includegraphics[width=0.8\textwidth]{worstcase.png}
    \label{fig:quadratic}
\end{figure}

Além disso, evidencio que o algoritmo incremental determinístico é de fato quadrático
na entrada construída. Para evidenciar o comportamento quadrático, a imagem na figura
\ref{fig:quadratic} acompanha a curva $y = x^2/4$ em azul, além do tempo de execução
nos casos construídos, em laranja.

\printbibliography

\end{document}
